{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import clip\n",
    "from clip.simple_tokenizer import SimpleTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CLIP / model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device, jit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathologyPairDataset(data.Dataset): \n",
    "    def __init__(\n",
    "        self, \n",
    "        img_dir: Path, \n",
    "        txt_dir: Path, \n",
    "        case_ids: List[int], \n",
    "        transform = None, \n",
    "    ): \n",
    "        \"\"\"\n",
    "        img_dir and txt_dir. \n",
    "\n",
    "        Use case_ids to perform train_test split at the start,\n",
    "        can choose which cases are actually read in\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.txt_dir = txt_dir\n",
    "        self.case_ids = case_ids\n",
    "        self.transform = transform\n",
    "\n",
    "        # len determined by number of image paths\n",
    "        self.img_paths = list(img_dir.rglob(\"*/*.png\") )\n",
    "        self.txt_paths = list(txt_dir.rglob(\"*.txt\"))\n",
    "        \n",
    "        self.case2txt = defaultdict(str)\n",
    "        for txt_path in self.txt_paths: \n",
    "            case_id = str(txt_path.stem).split(\".\")[0]\n",
    "            if case_id in case_ids:\n",
    "                self.case2txt[case_id] = txt_path\n",
    "        \n",
    "        # amortize case lookup\n",
    "        self.img_txt_pairs = []\n",
    "        for img_path in self.img_paths: \n",
    "            case_id = \"-\".join(str(img_path.stem).split(\".\")[0].split(\"-\")[:3])\n",
    "            if case_id in case_ids:\n",
    "                self.img_txt_pairs.append((img_path, self.case2txt[case_id]))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.img_txt_pairs)\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        img_path, txt_path = self.img_txt_pairs[idx]\n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        with open(txt_path, \"r\") as f: \n",
    "            txt = f.read()\n",
    "\n",
    "        return img, txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of dataset:  76252\n"
     ]
    }
   ],
   "source": [
    "img_dir = Path(\"./data/patches/10.0_224\")\n",
    "txt_dir = Path(\"./data/reports/\")\n",
    "# read in from csv, sample one from each class\n",
    "labels_path = Path(\"./data\") / \"labels_40.csv\"\n",
    "labels_df = pd.read_csv(labels_path)\n",
    "all_cases = list(labels_df[\"Case ID\"])\n",
    "\n",
    "dataset = PathologyPairDataset(\n",
    "    img_dir=img_dir, \n",
    "    txt_dir=txt_dir,\n",
    "    case_ids=all_cases,\n",
    "    transform=preprocess, \n",
    ")\n",
    "print(\"Len of dataset: \", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loader\n",
    "batch_size: int = 64\n",
    "shuffle: int = True\n",
    "num_workers: int = 4\n",
    "\n",
    "loader_params = {\n",
    "    'batch_size': batch_size, \n",
    "    'shuffle': shuffle, \n",
    "    'num_workers': num_workers, \n",
    "}\n",
    "data_loader = data.DataLoader(dataset, **loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(texts, model):\n",
    "    _tokenizer = SimpleTokenizer()\n",
    "    sot_token = _tokenizer.encoder[\"<|startoftext|>\"]\n",
    "    eot_token = _tokenizer.encoder[\"<|endoftext|>\"]\n",
    "    all_tokens = [[sot_token] + _tokenizer.encode(text) + [eot_token] for text in texts]\n",
    "    result = torch.zeros(len(all_tokens), model.context_length, dtype=torch.long)\n",
    "    \n",
    "    # will trim tokens to match context length\n",
    "    for i, tokens in enumerate(all_tokens):\n",
    "        if len(tokens) > model.context_length:\n",
    "            tokens = tokens[:model.context_length]\n",
    "            tokens[model.context_length - 1] = eot_token\n",
    "        result[i, :len(tokens)] = torch.tensor(tokens)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr: float = 1e-4\n",
    "momentum: float = 0.9\n",
    "epochs: int = 4\n",
    "log_interval: int = 10\n",
    "save_interval: int = 100\n",
    "save_dir: Path = Path(\"./checkpoints\")\n",
    "model_name: str = \"sample_0\"\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, device, criterion, optimizer, **kwargs): \n",
    "    model_save_dir = save_dir / model_name\n",
    "    model_save_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # Run training\n",
    "    total_batches = len(loader) * epochs\n",
    "    example_ct = 0  # number of examples seen\n",
    "    batch_ct = 0\n",
    "    report_freq = log_interval\n",
    "    highest_val_auc = 0 # save highest mean auc\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0 # running loss over batch\n",
    "        for data in tqdm(loader):\n",
    "            # get the images\n",
    "            images, texts = data\n",
    "            texts = preprocess_text(texts, model) \n",
    "            \n",
    "            # perform step for a single batch\n",
    "            loss = train_batch(images, texts, model, device, criterion, optimizer)\n",
    "            example_ct +=  len(images)\n",
    "            batch_ct += 1\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Report metrics every `report_freq` batch\n",
    "            if (batch_ct % report_freq) == 0:\n",
    "                train_log(running_loss / report_freq, example_ct, epoch)\n",
    "                running_loss = 0.0\n",
    "            \n",
    "            if (batch_ct % save_interval) == 0: \n",
    "                model_path = model_save_dir / f\"checkpoint_{str(batch_ct)}.pt\"\n",
    "                print(\"Saved checkpoint to: \", model_path)\n",
    "                save(model, model_path)\n",
    "                \n",
    "def train_batch(images, texts, model, device, criterion, optimizer):\n",
    "    images, texts = images.to(device), texts.to(device)\n",
    "    \n",
    "    # Forward pass ➡\n",
    "    logits_per_image, logits_per_text = model(images, texts)\n",
    "    \n",
    "    # Create labels\n",
    "    batch_size = images.shape[0]\n",
    "    labels = torch.arange(batch_size).to(device)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss_img = criterion(logits_per_image, labels)\n",
    "    loss_txt = criterion(logits_per_text, labels)\n",
    "    loss = (loss_img + loss_txt)/2 # avg. img and txt loss\n",
    "\n",
    "    # Backward pass ⬅\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step with optimizer\n",
    "    optimizer.step()\n",
    "        \n",
    "    return loss\n",
    "\n",
    "def train_log(loss, example_ct, epoch):\n",
    "    loss = float(loss)\n",
    "    print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\")\n",
    "    \n",
    "def save(model, path): \n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1192 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts: tensor([[49406, 15715,   281,  ...,  1150, 12544, 49407],\n",
      "        [49406, 15715,   281,  ...,     0,     0,     0],\n",
      "        [49406, 15715, 20616,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [49406, 49407,     0,  ...,     0,     0,     0],\n",
      "        [49406, 15715,   281,  ...,  1150, 12544, 49407],\n",
      "        [49406, 49407,     0,  ...,     0,     0,     0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1192 [00:01<21:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts: tensor([[49406, 49407,     0,  ...,     0,     0,     0],\n",
      "        [49406, 15715,   281,  ...,  8437,  9313, 49407],\n",
      "        [49406, 49407,     0,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [49406, 15715,   281,  ...,  4178,   631, 49407],\n",
      "        [49406, 15715,   267,  ...,  6262, 15715, 49407],\n",
      "        [49406, 15715,    25,  ...,   593,  1653, 49407]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1192 [00:01<13:35,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts: tensor([[49406, 49407,     0,  ...,     0,     0,     0],\n",
      "        [49406, 49407,     0,  ...,     0,     0,     0],\n",
      "        [49406, 15715,   281,  ..., 15368,   269, 49407],\n",
      "        ...,\n",
      "        [49406, 15715,   281,  ...,  4178,   631, 49407],\n",
      "        [49406, 49407,     0,  ...,     0,     0,     0],\n",
      "        [49406, 15715, 20616,  ...,     0,     0,     0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1192 [00:01<11:21,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts: tensor([[49406, 15715,    25,  ...,   593,  1653, 49407],\n",
      "        [49406, 49407,     0,  ...,     0,     0,     0],\n",
      "        [49406, 15715,    25,  ...,   593,  1653, 49407],\n",
      "        ...,\n",
      "        [49406, 15715,   281,  ...,  1150, 12544, 49407],\n",
      "        [49406, 49407,     0,  ...,     0,     0,     0],\n",
      "        [49406, 15715,  1474,  ...,  5306, 40534, 49407]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1192 [00:02<10:40,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts: tensor([[49406, 15715,   281,  ...,  4178,   631, 49407],\n",
      "        [49406, 49407,     0,  ...,     0,     0,     0],\n",
      "        [49406, 15715,   281,  ...,  1150, 12544, 49407],\n",
      "        ...,\n",
      "        [49406, 15715,   281,  ..., 22616, 16439, 49407],\n",
      "        [49406, 49407,     0,  ...,     0,     0,     0],\n",
      "        [49406, 49407,     0,  ...,     0,     0,     0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1192 [00:02<09:55,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts: tensor([[49406, 49407,     0,  ...,     0,     0,     0],\n",
      "        [49406, 15715,   281,  ...,  8437,  9313, 49407],\n",
      "        [49406, 49407,     0,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [49406, 49407,     0,  ...,     0,     0,     0],\n",
      "        [49406, 49407,     0,  ...,     0,     0,     0],\n",
      "        [49406, 15715, 20616,  ...,     0,     0,     0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1192 [00:03<09:25,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts: tensor([[49406, 15715,   261,  ..., 21010,   533, 49407],\n",
      "        [49406, 15715,   261,  ..., 21010,   533, 49407],\n",
      "        [49406, 49407,     0,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [49406, 15715,  5896,  ...,     0,     0,     0],\n",
      "        [49406, 15715,   261,  ..., 21010,   533, 49407],\n",
      "        [49406, 49407,     0,  ...,     0,     0,     0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1192 [00:03<12:18,  1.61it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[75], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loader, device, criterion, optimizer, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtexts:\u001b[39m\u001b[38;5;124m\"\u001b[39m, texts)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# perform step for a single batch\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m example_ct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mlen\u001b[39m(images)\n\u001b[1;32m     23\u001b[0m batch_ct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[75], line 56\u001b[0m, in \u001b[0;36mtrain_batch\u001b[0;34m(images, texts, model, device, criterion, optimizer)\u001b[0m\n\u001b[1;32m     53\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Step with optimizer\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/optimizer.py?line=137'>138</a>\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/optimizer.py?line=138'>139</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/optimizer.py?line=139'>140</a>\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/optimizer.py?line=140'>141</a>\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/optimizer.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/optimizer.py?line=20'>21</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/optimizer.py?line=21'>22</a>\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/optimizer.py?line=22'>23</a>\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/optimizer.py?line=23'>24</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/optimizer.py?line=24'>25</a>\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py:151\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=147'>148</a>\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=148'>149</a>\u001b[0m             momentum_buffer_list\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmomentum_buffer\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=150'>151</a>\u001b[0m sgd(params_with_grad,\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=151'>152</a>\u001b[0m     d_p_list,\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=152'>153</a>\u001b[0m     momentum_buffer_list,\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=153'>154</a>\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=154'>155</a>\u001b[0m     momentum\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmomentum\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=155'>156</a>\u001b[0m     lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=156'>157</a>\u001b[0m     dampening\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdampening\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=157'>158</a>\u001b[0m     nesterov\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mnesterov\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=158'>159</a>\u001b[0m     maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=159'>160</a>\u001b[0m     has_sparse_grad\u001b[39m=\u001b[39;49mhas_sparse_grad,\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=160'>161</a>\u001b[0m     foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=162'>163</a>\u001b[0m \u001b[39m# update momentum_buffers in state\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=163'>164</a>\u001b[0m \u001b[39mfor\u001b[39;00m p, momentum_buffer \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(params_with_grad, momentum_buffer_list):\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py:202\u001b[0m, in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=198'>199</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=199'>200</a>\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_sgd\n\u001b[0;32m--> <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=201'>202</a>\u001b[0m func(params,\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=202'>203</a>\u001b[0m      d_p_list,\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=203'>204</a>\u001b[0m      momentum_buffer_list,\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=204'>205</a>\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=205'>206</a>\u001b[0m      momentum\u001b[39m=\u001b[39;49mmomentum,\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=206'>207</a>\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=207'>208</a>\u001b[0m      dampening\u001b[39m=\u001b[39;49mdampening,\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=208'>209</a>\u001b[0m      nesterov\u001b[39m=\u001b[39;49mnesterov,\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=209'>210</a>\u001b[0m      has_sparse_grad\u001b[39m=\u001b[39;49mhas_sparse_grad,\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=210'>211</a>\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py:245\u001b[0m, in \u001b[0;36m_single_tensor_sgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=241'>242</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=242'>243</a>\u001b[0m         d_p \u001b[39m=\u001b[39m buf\n\u001b[0;32m--> <a href='file:///opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/sgd.py?line=244'>245</a>\u001b[0m param\u001b[39m.\u001b[39;49madd_(d_p, alpha\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49mlr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, data_loader, device, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
